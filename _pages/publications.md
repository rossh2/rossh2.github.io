---
title: Publications
permalink: /publications/
toc: true
---

## Papers, Conference Talks and Proceedings

### 2024

**Hayley Ross**, Kathryn Davidson and Najoung Kim (_accepted for publication_). ‘Is artificial intelligence still intelligence? LLMs generalize to novel adjective-noun pairs, but don’t mimic the full human distribution’. Proceedings of the 2nd GenBench Workshop on (Benchmarking) Generalisation in NLP. Association for Computational Linguistics, Miami, United States. [\[Slides\]](https://docs.google.com/presentation/d/164-qw81zR8bpiLyC5pL1emIb1L34PvMnlJZF7awS4Qo/edit?usp=sharing) [\[Preprint\]](https://arxiv.org/abs/2410.17482)

**Hayley Ross**, Najoung Kim and Kathryn Davidson (_accepted for publication_). ‘Fake reefs are sometimes reefs and sometimes not, but are always compositional’. Experiments in Linguistic Meaning 3. Philadelphia, United States. [\[Slides\]](https://docs.google.com/presentation/d/1S9PXYFUOFRAhwnx-5ELnD78BZ4OYgvDH2WEGNcIVVPs/edit?usp=sharing) [\[Preprint\]](https://lingbuzz.net/lingbuzz/008012)

### 2023

**Hayley Ross**, Gennaro Chierchia and Kathryn Davidson (2023). ‘Quantifying weak and strong crossover for _wh_-crossover and proper names’. Sinn und Bedeutung 27. Prague, Czech Republic.  [\[Slides\]](/assets/publications/Ross-et-al_SuB_Crossover_Presentation.pdf) [\[Paper\]](https://ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/1085)

Bonan Min, **Hayley Ross**, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre, Ilana Heinz and Dan Roth (2023). Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey. ACM Computing Surveys. [https://doi.org/10.1145/3605943](https://doi.org/10.1145/3605943) [\[arXiv preprint (2021)\]](https://arxiv.org/abs/2111.01243)


### 2022

**Hayley Ross** (2022). ‘Implications of the Danish Definiteness Alternation for Concord in Nanosyntax’. SinFonIJA 14 (virtual). [\[Link\]](https://godisnjak.ff.uns.ac.rs/index.php/gff/article/view/2270/2211)

### 2020

**Hayley Ross**, Jonathon Cai, and Bonan Min (2020). ‘Exploring Contextualized Neural Language Models for Temporal Dependency Parsing’. Pp. 8548–53 in <i>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</i>. [\[Link\]](https://www.aclweb.org/anthology/2020.emnlp-main.689)

**Hayley Ross** (2020). ‘The Falsity of the Consequent in Contrastive Conditionals’. in <i>Proceedings of the ESSLLI &amp; WeSSLLI Student Session 2020</i>. Brandeis University, Waltham, MA. [\[Link\]](https://www.brandeis.edu/nasslli2020/pdfs/student-session-proceedings-compressed.pdf)

## Manuscripts and Work in Progress

**Hayley Ross** (2024). ‘New experiments on indefinite crossover’. Squib for LING 207, Topics in Semantics, taught by Gennaro Chierchia and Kathryn Davidson in Spring 2024.  [\[Squib\]](LING207-IndefiniteCrossover-Squib.pdf)  [\[Slides with experiment results\]](/assets/publications/IndefiniteCrossoverPreliminaryResults.pdf)  [\[Experiment items (xlsx)\]](/assets/publications/IndefiniteCrossoverExperimentExamples.xlsx)

<p style="font-size: 0.7em !important">We conducted follow-up work to Ross, Davidson and Chierchia (2023) to further investigate weak crossover with proper names and indefinites. What we found, surprisingly, is that discourse/information structure may ameliorate or entirely remove effects of weak crossover not just for proper names (as suggested by previous literature), but also potentially for indefinites and universal quantifiers, if the experiment is correct. The results, however, are difficult to interpret, and it is difficult to design an experiment to probe this effectively. I'm sharing the initial, unpublished results here in the hope that someone else will find this useful and be able to continue this work.</p>

**Hayley Ross** (2022). ‘The landscape of German definites and demonstratives’. Squib for LING 207, Topics in Semantics, taught by Gennaro Chierchia and Yağmur Sağ in Spring 2022.  [\[Link\]](/assets/publications/GermanDemonstratives-Squib_revised.pdf)

<p style="font-size: 0.7em !important">I wrote a squib on demonstratives and strong definites in German and Swiss German, which contains a more comprehensive overview of the data in Standard and Swiss German than I'm aware of in any other literature. While the theoretical implications remain to be worked out, by sharing this, hopefully other people can work with this data.</p>


