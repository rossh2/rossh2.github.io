---
title: About Hayley
permalink: /about/
layout: single
---

I'm a third year PhD student in the Department of Linguistics at Harvard University with a dream of combining theoretical semantics with computational linguistics. 

I have a deep love for theory and formalisms, with a soft spot for lambda calculus, fancy operators and continuation semantics.
I'm currently pursuing projects in theoretical and experimental semantics on anaphora and indefinites, specifically on crossover and the handling of indefinites and discourse referents. I'm in the middle of a series of experiments on crossover aimed at laying the groundwork for wh-crossover and quantificational crossover &ndash; there's actually surprisingly little experimental data on crossover. We've been able to find a significant empirical difference in naive native speakers between strong and weak crossover, suggesting that theories need to account for these phenomena separately. With these results in hand, we can also compare how proper names and indefinites behave in the same situations. Proper names, at least, seem to show a similar crossover effect when used with cataphora, suggesting that something like Rule I is indeed needed.

I'm always interested in the debate of whether we need linguistics for natural language processing. I would argue that we do! Linguistics lets us understand the strengths and limitations of large neural language models by giving us a well-understood set of phenomena to measure language models by, and can help us pinpoint ways in which language models are not, in fact, modelling human language the way we do. Moreover, linguistic typology gives us a principled way to structure cross-lingual transfer learning. I'm also very interested in the question of whether NLP and language acquisition are converging &ndash; whether the trending "more data and bigger models" approach to NLP will ever produce a human-like approach to language, or whether we will turn back to building hybrid systems which enforce syntactic, semantic or pragmatic structure in order to learn language with the mechanisms children use to learn, with vastly less data than their neural network counterparts. Is it possible to learn human-like language without being immersed in a human-like world?

In the meantime, I'm deeply interested in what modern language models understand about language. We know that models like GPT-3 or T5 can tell plausible stories, provide convincing explanations of both facts and jokes and write short essays at the level of the average high-schooler. But does reading the entirety of the internet really teach them all the subtle rules of language that humans subsconsciously apply, or are they just able to parrot common constructions and snippets of sentences? What does it mean for a language model to "know" or "understand" language? 
I'm currently collaborating with Jacob Andreas and a group of researchers at MIT across computer and cognitive science to answer these questions. My work focuses on a range of syntax-semantics mapping phenomena centred around thematic roles, and our goal as a group is to build up a broad dataset capturing what language models understand about meaning.

When I'm not doing research, you can find me reading, hiking (ideally in the Swiss Alps!) and spoiling my fluffy black cat, Aurora. If you ever need a native Swiss German (or British English) speaker for your research, let me know.
